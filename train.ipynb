{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f391be7f",
            "metadata": {},
            "source": "# Building the model"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cdf5d6df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "import os\nimport json\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.optim.lr_scheduler import StepLR\n\nimport preproc"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fb3d261c",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "N_EPOCHS = 100\nBATCH_SIZE = 64\n\ncols = ['latitude', 'longitude', 'timestamp']"
        },
        {
            "cell_type": "markdown",
            "id": "be90f19c",
            "metadata": {},
            "source": "## Load the dataset"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2460a48b",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "data_dir = 'dataset/preprocessed'\ntrain = np.load(os.path.join(data_dir, 'train.npy'))\nvalid = np.load(os.path.join(data_dir, 'valid.npy'))\ntest = np.load(os.path.join(data_dir, 'test.npy'))\n\nbounds = {}\nbounds_path = os.path.join(data_dir, 'bounds.json')\nwith open(bounds_path) as file:\n    bounds = json.load(file)"
        },
        {
            "cell_type": "markdown",
            "id": "1b88cf71",
            "metadata": {},
            "source": "# Create the model"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c52d93cd",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nevent_vec_dim = train.shape[-1]\nseq_len = preproc.WINDOW_SIZE\nhidden_dim = 1024\nnum_layers = 4"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e3a3a20a",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "from lstm_model import FirePredictor\n\n# create the model\nmodel = FirePredictor(event_vec_dim, seq_len, hidden_dim, num_layers)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "201b9147",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# visualize model structure\n# This uses torchview, which is a library outside of pytorch for visualizing torch.nn.Modules\n# https://github.com/mert-kurttutan/torchview\nimport graphviz\ngraphviz.set_jupyter_format('png')\n\nfrom torchview import draw_graph\nmodel_graph = draw_graph(model, input_size=(BATCH_SIZE, seq_len, event_vec_dim), device='cuda')\nmodel_graph.visual_graph"
        },
        {
            "cell_type": "markdown",
            "id": "dcf117bb",
            "metadata": {},
            "source": "## Write the loss function"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e703fe04",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# def euclidean_dist(t1, t2, dim):\n#     return (t1 - t2).pow(2).sum(dim).sqrt()\n#\n# def avg_distance(x, y):\n#     if x.isnan().any():\n#         print(x)\n#         raise RuntimeError(\"Loss func: x contains NAN\")\n#     # use nearest neighbor upsampling\n#     reshaped = torch.nn.functional.interpolate(x[:,:,None,:], size=y.shape[2:], mode='nearest')\n#     if reshaped.isnan().any():\n#         print(reshaped)\n#         raise RuntimeError(\"Loss func: reshaped x contains NAN\")\n#     result = (euclidean_dist(reshaped, y, dim=2)).sum() / np.array(y.shape[0:-1]).prod()\n#     if result.isnan().any():\n#         print(result)\n#         raise RuntimeError(\"Loss func: result contains NAN\")\n#     return result\n#\n#\n# x = torch.Tensor(sequences[0:3,0:64,0,:])\n# y = torch.Tensor(sequences[0:3,0:64,1:,:])\n#\n# print(avg_distance(torch.Tensor(x), torch.Tensor(y)))\n# print(f'{x.shape=}, {y.shape=}')"
        },
        {
            "cell_type": "markdown",
            "id": "197e3477",
            "metadata": {},
            "source": "## Prepare Optimizer, Scheduler, and Data Loader"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4bc457a8",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# split train & validation data into inputs and labels\nx_train = torch.Tensor(train[:,:64,:])\ny_train = torch.Tensor(train[:,64,:])\n\nx_valid = torch.Tensor(valid[:,:64,:]).to(device)\ny_valid = torch.Tensor(valid[:,64,:]).to(device)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "418d110b",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "print(f'{x_valid.shape=}, {y_valid.shape}')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d6feedd0",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "optimizer = torch.optim.SGD(model.parameters(), lr=0.03, momentum=0.9)\n\nscheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n\ndata_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n\nloss_function = nn.MSELoss()"
        },
        {
            "cell_type": "markdown",
            "id": "1f020fe0",
            "metadata": {},
            "source": "## Training Loop"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f185803e",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "losses_valid = np.zeros(N_EPOCHS)\nlosses_train = np.zeros(N_EPOCHS)\n\nfor epoch in range(N_EPOCHS):\n    # loop over batches\n    acc_train_loss = 0.0\n    for i, data in enumerate(data_loader):\n\n        x_batch, y_batch = data\n        x_batch = x_batch.to(device)\n        y_batch = y_batch.to(device)\n\n        optimizer.zero_grad()\n\n        preds = model(x_batch)\n\n        loss = loss_function(preds, y_batch)\n        acc_train_loss += loss\n        loss.backward()\n\n        optimizer.step()\n\n    # record average loss of all batches in this epoch\n    losses_train[epoch] = acc_train_loss / (x_train.shape[0]/BATCH_SIZE)\n\n    # compute validation loss\n    model.eval()\n    with torch.no_grad():\n        v_preds = model(x_valid)\n        losses_valid[epoch] = loss_function(v_preds, y_valid).item()\n    model.train()\n\n    # print out the losses so we can see it update as we train\n    print(f'Epoch {epoch} -- train loss: {losses_train[epoch]} valid loss: {losses_valid[epoch]}')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b32ab892",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "model(x_train[0][None, :, :].to(device))"
        },
        {
            "cell_type": "markdown",
            "id": "50d5f349",
            "metadata": {},
            "source": "## Analyze the results"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6c0ad8c2",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "import matplotlib.pyplot as plt\nplt.plot(losses_train, label='train loss')\nplt.plot(losses_valid, label='validation loss', color='r')\nplt.legend()\n\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1649d831",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "model.eval()\nwith torch.no_grad():\n    res = model(x_train[0:128].to(device)).cpu().detach()\n    res = pd.DataFrame(res, columns=cols)\n\nprediction = preproc.unprocess(res, bounds)\nactual = preproc.unprocess(pd.DataFrame(y_train[0:128].numpy(), columns=cols), bounds)\n\ndisplay(prediction)\ndisplay(actual)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8de378eb",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "display(prediction.sort_values('timestamp'))\ndisplay(actual.sort_values('timestamp'))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "61872548",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "display(prediction.std(axis=0))\ndisplay(actual.std(axis=0))"
        },
        {
            "cell_type": "markdown",
            "id": "4023d1ae",
            "metadata": {},
            "source": "# Save the model's state_dict to a JSON file to evaluate later"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b69609e6",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "model_file = \"models/single_lstm.json\"\nmodel.to_json(model_file)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a66eedde",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "# load the model, just to be sure that we can\nmodel.from_json(model_file)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d5a0de53",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "model.eval()\nwith torch.no_grad():\n    res = model(x_train[0:128].to(device)).cpu().detach()\n    res = pd.DataFrame(res, columns=cols)\n\npred2 = preproc.unprocess(res, bounds)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6a9e3797",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "display(prediction.sort_values('timestamp'))\ndisplay(pred2.sort_values('timestamp'))"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}